{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT-01.ipynb","provenance":[],"authorship_tag":"ABX9TyNqXmb2bGKjzGI9fI7j6wt1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7bdc03ce61574c61990c857c185871b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_40ed58f8988c4694a416ea68d66c1304","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9693d42f39cf4b1aa98b2a661cf24ada","IPY_MODEL_5abc9cfac1e04179af8d329236aee3a0"]}},"40ed58f8988c4694a416ea68d66c1304":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9693d42f39cf4b1aa98b2a661cf24ada":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b249c90a3331422d81b3eaf1f3e92b15","_dom_classes":[],"description":"Loading:  28%","_model_name":"FloatProgressModel","bar_style":"danger","max":3724301,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1039716,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bbb6d71e3af44079ab9bede280621359"}},"5abc9cfac1e04179af8d329236aee3a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bcfe75f8a51143ccba6e53854521f5be","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1039716/3724301 [03:07&lt;08:05, 5534.06it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_28937a8a7c1c4395bdb67258bf6d6428"}},"b249c90a3331422d81b3eaf1f3e92b15":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bbb6d71e3af44079ab9bede280621359":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcfe75f8a51143ccba6e53854521f5be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"28937a8a7c1c4395bdb67258bf6d6428":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2fd456dcda884509ae4193b116548c83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cc4c49ee557a4894ae7434e2654c09b4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a41b8eb0f737439d8763761e1a9f4a2f","IPY_MODEL_759875c49b374910bd97be66b32a675f"]}},"cc4c49ee557a4894ae7434e2654c09b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a41b8eb0f737439d8763761e1a9f4a2f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0abeb44ca5e34b4d9ebc0f9662a7439f","_dom_classes":[],"description":"Making: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":100001,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":100001,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_653bde8d60f54ecca3c88336c43f790a"}},"759875c49b374910bd97be66b32a675f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_36c4819add474a7099828694b1029ea0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 100001/100001 [01:57&lt;00:00, 847.55it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_589d526e85594f4e9ad8ead4dfb8343f"}},"0abeb44ca5e34b4d9ebc0f9662a7439f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"653bde8d60f54ecca3c88336c43f790a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"36c4819add474a7099828694b1029ea0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"589d526e85594f4e9ad8ead4dfb8343f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"heuH9bvye9wX"},"source":["# **Implement BERT**\r\n","paper: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"]},{"cell_type":"markdown","metadata":{"id":"7JtWiyNNfjHl"},"source":["![](https://paul-hyun.github.io/assets/2020-01-02/bert-pretrain.png)"]},{"cell_type":"code","metadata":{"id":"hJx-Hfs-e7Va","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614827625105,"user_tz":-540,"elapsed":4989,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}},"outputId":"8f27271b-8175-4087-b172-2d030d484699"},"source":["!pip install sentencepiece\r\n","!pip install wget"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n","Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jsn78VJ_fvwF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614827625108,"user_tz":-540,"elapsed":4976,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}},"outputId":"b6a8fd60-4254-4b9f-8709-e6d85a33d32a"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')\r\n","data_dir = '/content/drive/My Drive/Data/ML tutorial'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rtL4Z0Maf168","executionInfo":{"status":"ok","timestamp":1614827625380,"user_tz":-540,"elapsed":5239,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["import os\r\n","import numpy as np\r\n","import math\r\n","from random import random, randrange, randint, shuffle, choice\r\n","import matplotlib.pyplot as plt\r\n","import json\r\n","import pandas as pd\r\n","from IPython.display import display\r\n","from tqdm import tqdm, tqdm_notebook, trange\r\n","import sentencepiece as spm\r\n","import wget\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"fk-gfp8Xf_VF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614827625384,"user_tz":-540,"elapsed":5234,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}},"outputId":"f496ef54-7786-4679-cb4e-3a6029518a96"},"source":["for f in os.listdir(data_dir):\r\n","  print(f)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["kowiki.txt\n","kowiki.model\n","kowiki.vocab\n","ratings_train.txt\n","ratings_test.txt\n","ratings_train.json\n","ratings_test.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"brxChyN7f51u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614827625386,"user_tz":-540,"elapsed":5226,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}},"outputId":"5540102f-2518-4e99-892a-c23fe43ce44c"},"source":["vocab_file = f\"{data_dir}/kowiki.model\"\r\n","vocab = spm.SentencePieceProcessor()\r\n","vocab.load(vocab_file)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"a0JubmScgE74"},"source":["Set Config"]},{"cell_type":"code","metadata":{"id":"1ypXCk3pptkt","executionInfo":{"status":"ok","timestamp":1614827625387,"user_tz":-540,"elapsed":5219,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["class Config(dict):\r\n","  __getattr__ = dict.__getitem__\r\n","  __setattr__ = dict.__setitem__\r\n","\r\n","  @classmethod\r\n","  def load(cls, file):\r\n","    with open(file, 'r') as f:\r\n","      config = json.loads(f.read())\r\n","      return Config(config)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ukKudIFaf8_3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614827625388,"user_tz":-540,"elapsed":5215,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}},"outputId":"999953a3-1379-48a6-e8c9-f304308bdef1"},"source":["config = Config({\r\n","    \"n_enc_vocab\": len(vocab),\r\n","    \"n_enc_seq\": 256,\r\n","    \"n_seg_type\": 2,\r\n","    \"n_layer\": 6,\r\n","    \"d_hidn\": 256,\r\n","    \"i_pad\": 0,\r\n","    \"d_ff\": 1024,\r\n","    \"n_head\": 4,\r\n","    \"d_head\": 64,\r\n","    \"dropout\": 0.1,\r\n","    \"layer_norm_epsilon\": 1e-12\r\n","})\r\n","print(config)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["{'n_enc_vocab': 8007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tdBpI5F3FT0Q"},"source":["## Implement BERT using codes from [Transformer-02](https://github.com/ionheart26/Machine-Learning-tutorial/blob/master/Transformer-02.ipynb)"]},{"cell_type":"code","metadata":{"id":"qhJ0k5eVsUSj","executionInfo":{"status":"ok","timestamp":1614827625642,"user_tz":-540,"elapsed":5463,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["\"\"\" sinusoid position encoding \"\"\"\r\n","def get_sinusoid_encoding_table(n_seq, d_hidn):\r\n","    def cal_angle(position, i_hidn):\r\n","        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\r\n","    def get_posi_angle_vec(position):\r\n","        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\r\n","\r\n","    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\r\n","    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \r\n","    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\r\n","\r\n","    return sinusoid_table\r\n","\r\n","def get_attn_pad_mask(seq_q, seq_k, i_pad):\r\n","      batch_size, len_q = seq_q.size()\r\n","      batch_size, len_k = seq_k.size()\r\n","      pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)\r\n","      return pad_attn_mask\r\n","\r\n","def get_attn_decoder_mask(seq):\r\n","  subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\r\n","  subsequent_mask = subsequent_mask.triu(diagonal=1)\r\n","  return subsequent_mask\r\n","\r\n","class ScaledDotProductAttention(nn.Module):\r\n","    def __init__(self, config):\r\n","        super().__init__()\r\n","        self.config = config\r\n","        self.dropout = nn.Dropout(config.dropout)\r\n","        self.scale = 1 / (self.config.d_head ** 0.5)\r\n","    \r\n","    def forward(self, Q, K, V, attn_mask):\r\n","        # (bs, n_head, n_q_seq, n_k_seq)\r\n","        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\r\n","        scores.masked_fill_(attn_mask, -1e9)\r\n","        # (bs, n_head, n_q_seq, n_k_seq)\r\n","        attn_prob = nn.Softmax(dim=-1)(scores)\r\n","        attn_prob = self.dropout(attn_prob)\r\n","        # (bs, n_head, n_q_seq, d_v)\r\n","        context = torch.matmul(attn_prob, V)\r\n","        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\r\n","        return context, attn_prob\r\n","\r\n","class MultiHeadAttention(nn.Module):\r\n","    def __init__(self, config):\r\n","        super().__init__()\r\n","        self.config = config\r\n","\r\n","        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\r\n","        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\r\n","        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\r\n","        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\r\n","        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\r\n","        self.dropout = nn.Dropout(config.dropout)\r\n","    \r\n","    def forward(self, Q, K, V, attn_mask):\r\n","        batch_size = Q.size(0)\r\n","        # (bs, n_head, n_q_seq, d_head)\r\n","        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\r\n","        # (bs, n_head, n_k_seq, d_head)\r\n","        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\r\n","        # (bs, n_head, n_v_seq, d_head)\r\n","        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\r\n","\r\n","        # (bs, n_head, n_q_seq, n_k_seq)\r\n","        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\r\n","\r\n","        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\r\n","        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\r\n","        # (bs, n_head, n_q_seq, h_head * d_head)\r\n","        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\r\n","        # (bs, n_head, n_q_seq, e_embd)\r\n","        output = self.linear(context)\r\n","        output = self.dropout(output)\r\n","        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\r\n","        return output, attn_prob\r\n","\r\n","class PoswiseFeedForwardNet(nn.Module):\r\n","    def __init__(self, config):\r\n","        super().__init__()\r\n","        self.config = config\r\n","\r\n","        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\r\n","        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\r\n","        self.active = F.gelu\r\n","        self.dropout = nn.Dropout(config.dropout)\r\n","\r\n","    def forward(self, inputs):\r\n","        # (bs, d_ff, n_seq)\r\n","        output = self.active(self.conv1(inputs.transpose(1, 2)))\r\n","        # (bs, n_seq, d_hidn)\r\n","        output = self.conv2(output).transpose(1, 2)\r\n","        output = self.dropout(output)\r\n","        # (bs, n_seq, d_hidn)\r\n","        return output"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"8CRkzDUF4GsY","executionInfo":{"status":"ok","timestamp":1614827625649,"user_tz":-540,"elapsed":5466,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["class EncoderLayer(nn.Module):\r\n","    def __init__(self, config):\r\n","        super().__init__()\r\n","        self.config = config\r\n","\r\n","        self.self_attn = MultiHeadAttention(self.config)\r\n","        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\r\n","        self.pos_ffn = PoswiseFeedForwardNet(self.config)\r\n","        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\r\n","    \r\n","    def forward(self, inputs, attn_mask):\r\n","        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\r\n","        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\r\n","        att_outputs = self.layer_norm1(inputs + att_outputs)\r\n","        # (bs, n_enc_seq, d_hidn)\r\n","        ffn_outputs = self.pos_ffn(att_outputs)\r\n","        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\r\n","        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\r\n","        return ffn_outputs, attn_prob"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"rowRsZYp5uW-","executionInfo":{"status":"ok","timestamp":1614827625652,"user_tz":-540,"elapsed":5465,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["class Encoder(nn.Module):\r\n","    def __init__(self, config):\r\n","        super().__init__()\r\n","        self.config = config\r\n","\r\n","        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\r\n","        self.pos_emb = nn.Embedding(self.config.n_enc_seq + 1, self.config.d_hidn)\r\n","        self.seg_emb = nn.Embedding(self.config.n_seg_type, self.config.d_hidn)\r\n","\r\n","        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\r\n","    \r\n","    def forward(self, inputs, segments):\r\n","        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\r\n","        pos_mask = inputs.eq(self.config.i_pad)\r\n","        positions.masked_fill_(pos_mask, 0)\r\n","\r\n","        # (bs, n_enc_seq, d_hidn)\r\n","        outputs = self.enc_emb(inputs) + self.pos_emb(positions)  + self.seg_emb(segments)\r\n","\r\n","        # (bs, n_enc_seq, n_enc_seq)\r\n","        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\r\n","\r\n","        attn_probs = []\r\n","        for layer in self.layers:\r\n","            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\r\n","            outputs, attn_prob = layer(outputs, attn_mask)\r\n","            attn_probs.append(attn_prob)\r\n","        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\r\n","        return outputs, attn_probs"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"-J2-OOZV6p6k","executionInfo":{"status":"ok","timestamp":1614827625654,"user_tz":-540,"elapsed":5463,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["class BERT(nn.Module):\r\n","    def __init__(self, config):\r\n","        super().__init__()\r\n","        self.config = config\r\n","\r\n","        self.encoder = Encoder(self.config)\r\n","\r\n","        self.linear = nn.Linear(config.d_hidn, config.d_hidn)\r\n","        self.activation = torch.tanh\r\n","    \r\n","    def forward(self, inputs, segments):\r\n","        # (bs, n_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\r\n","        outputs, self_attn_probs = self.encoder(inputs, segments)\r\n","        # (bs, d_hidn)\r\n","        outputs_cls = outputs[:, 0].contiguous()\r\n","        outputs_cls = self.linear(outputs_cls)\r\n","        outputs_cls = self.activation(outputs_cls)\r\n","        # (bs, n_enc_seq, n_enc_vocab), (bs, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\r\n","        return outputs, outputs_cls, self_attn_probs\r\n","    \r\n","    def save(self, epoch, loss, path):\r\n","        torch.save({\r\n","            \"epoch\": epoch,\r\n","            \"loss\": loss,\r\n","            \"state_dict\": self.state_dict()\r\n","        }, path)\r\n","    \r\n","    def load(self, path):\r\n","        save = torch.load(path)\r\n","        self.load_state_dict(save[\"state_dict\"])\r\n","        return save[\"epoch\"], save[\"loss\"]"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dgfM1LQpFJNP"},"source":["## Pretrain Bert\r\n","![](https://paul-hyun.github.io/assets/2020-01-02/bert-mlm-nsp.png)"]},{"cell_type":"code","metadata":{"id":"oV2rpXti7Mq0","executionInfo":{"status":"ok","timestamp":1614827625656,"user_tz":-540,"elapsed":5461,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["class BERTPretrain(nn.Module):\r\n","    def __init__(self, config):\r\n","        super().__init__()\r\n","        self.config = config\r\n","\r\n","        self.bert = BERT(self.config)\r\n","        # classfier\r\n","        self.projection_cls = nn.Linear(self.config.d_hidn, 2, bias=False)\r\n","        # lm\r\n","        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_enc_vocab, bias=False)\r\n","        self.projection_lm.weight = self.bert.encoder.enc_emb.weight\r\n","    \r\n","    def forward(self, inputs, segments):\r\n","        # (bs, n_enc_seq, d_hidn), (bs, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\r\n","        outputs, outputs_cls, attn_probs = self.bert(inputs, segments)\r\n","        # (bs, 2)\r\n","        logits_cls = self.projection_cls(outputs_cls)\r\n","        # (bs, n_enc_seq, n_enc_vocab)\r\n","        logits_lm = self.projection_lm(outputs)\r\n","        # (bs, n_enc_vocab), (bs, n_enc_seq, n_enc_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)]\r\n","        return logits_cls, logits_lm, attn_probs"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pLEHcvE796Qa"},"source":["Make Pretrain data"]},{"cell_type":"code","metadata":{"id":"47eftnao9tcp","executionInfo":{"status":"ok","timestamp":1614827625658,"user_tz":-540,"elapsed":5459,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["def create_pretrain_mask(tokens, mask_cnt, vocab_list):\r\n","    '''\r\n","    Create pretrain mask for MLM\r\n","    tokens: a list of tokens, where each tokens are string type\r\n","    '''\r\n","    cand_idx = []\r\n","    for (i, token) in enumerate(tokens):\r\n","        if token == \"[CLS]\" or token == \"[SEP]\":\r\n","            continue\r\n","        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\r\n","            cand_idx[-1].append(i)\r\n","        else:\r\n","            cand_idx.append([i])\r\n","    shuffle(cand_idx)\r\n","\r\n","    mask_lms = []\r\n","    for index_set in cand_idx:\r\n","        if len(mask_lms) >= mask_cnt:\r\n","            break\r\n","        if len(mask_lms) + len(index_set) > mask_cnt:\r\n","            continue\r\n","        for index in index_set:\r\n","            masked_token = None\r\n","            if random() < 0.8: # 80% replace with [MASK]\r\n","                masked_token = \"[MASK]\"\r\n","            else:\r\n","                if random() < 0.5: # 10% keep original\r\n","                    masked_token = tokens[index]\r\n","                else: # 10% random word\r\n","                    masked_token = choice(vocab_list)\r\n","            mask_lms.append({\"index\": index, \"label\": tokens[index]})\r\n","            tokens[index] = masked_token\r\n","    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\r\n","    mask_idx = [p[\"index\"] for p in mask_lms]\r\n","    mask_label = [p[\"label\"] for p in mask_lms]\r\n","\r\n","    return tokens, mask_idx, mask_label"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"4C3SbB294jhu","executionInfo":{"status":"ok","timestamp":1614827625660,"user_tz":-540,"elapsed":5457,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["def trim_tokens(tokens_a, tokens_b, max_seq):\r\n","    while True:\r\n","        total_length = len(tokens_a) + len(tokens_b)\r\n","        if total_length <= max_seq:\r\n","            break\r\n","\r\n","        if len(tokens_a) > len(tokens_b):\r\n","            del tokens_a[0]\r\n","        else:\r\n","            tokens_b.pop()"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"hTuIdtiN4mFu","executionInfo":{"status":"ok","timestamp":1614827625891,"user_tz":-540,"elapsed":5684,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["def create_pretrain_instances(docs, doc_idx, doc, n_seq, mask_prob, vocab_list):\r\n","    '''\r\n","    Create pretrain instances for MLM and NSP.\r\n","    doc: a single document which is a list of lines, where each lines are list of tokens, and each tokens are string type.\r\n","    '''\r\n","    # for [CLS], [SEP], [SEP]\r\n","    max_seq = n_seq - 3\r\n","    tgt_seq = max_seq\r\n","    \r\n","    instances = []\r\n","    current_chunk = []\r\n","    current_length = 0\r\n","    for i in range(len(doc)):\r\n","        current_chunk.append(doc[i]) # line\r\n","        current_length += len(doc[i])\r\n","        if i == len(doc) - 1 or current_length >= tgt_seq:\r\n","            if 0 < len(current_chunk):\r\n","                a_end = 1 # index after token a\r\n","                if 1 < len(current_chunk):\r\n","                    a_end = randrange(1, len(current_chunk))\r\n","                tokens_a = []\r\n","                for j in range(a_end):\r\n","                    tokens_a.extend(current_chunk[j])\r\n","                \r\n","                tokens_b = []\r\n","                # make token b from random doc\r\n","                if len(current_chunk) == 1 or random() < 0.5:\r\n","                    is_next = 0\r\n","                    tokens_b_len = tgt_seq - len(tokens_a)\r\n","                    random_doc_idx = doc_idx\r\n","                    while doc_idx == random_doc_idx:\r\n","                        random_doc_idx = randrange(0, len(docs))\r\n","                    random_doc = docs[random_doc_idx]\r\n","\r\n","                    random_start = randrange(0, len(random_doc))\r\n","                    for j in range(random_start, len(random_doc)):\r\n","                        tokens_b.extend(random_doc[j])\r\n","                # make token b from next part of token a\r\n","                else:\r\n","                    is_next = 1\r\n","                    for j in range(a_end, len(current_chunk)):\r\n","                        tokens_b.extend(current_chunk[j])\r\n","\r\n","                trim_tokens(tokens_a, tokens_b, max_seq)\r\n","                assert 0 < len(tokens_a)\r\n","                assert 0 < len(tokens_b)\r\n","\r\n","                tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\r\n","                segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\r\n","\r\n","                tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\r\n","\r\n","                instance = {\r\n","                    \"tokens\": tokens,\r\n","                    \"segment\": segment,\r\n","                    \"is_next\": is_next,\r\n","                    \"mask_idx\": mask_idx,\r\n","                    \"mask_label\": mask_label\r\n","                }\r\n","                instances.append(instance)\r\n","\r\n","            current_chunk = []\r\n","            current_length = 0\r\n","    return instances"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"IUjnuXmf4tuA","executionInfo":{"status":"ok","timestamp":1614827625894,"user_tz":-540,"elapsed":5682,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["def make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob):\r\n","    vocab_list = []\r\n","    for id in range(vocab.get_piece_size()):\r\n","        if not vocab.is_unknown(id):\r\n","            vocab_list.append(vocab.id_to_piece(id))\r\n","\r\n","    line_cnt = 0\r\n","    with open(in_file, \"r\") as in_f:\r\n","        for line in in_f:\r\n","            line_cnt += 1\r\n","    \r\n","    docs = []\r\n","    with open(in_file, \"r\") as f:\r\n","        doc = []\r\n","        with tqdm_notebook(total=line_cnt, desc=f\"Loading\") as pbar:\r\n","            for i, line in enumerate(f):\r\n","                line = line.strip()\r\n","                if line == \"\":\r\n","                    if 0 < len(doc):\r\n","                        docs.append(doc)\r\n","                        doc = []\r\n","                        # 메모리 사용량을 줄이기 위해 100,000개만 처리 함\r\n","                        if 100000 < len(docs): break\r\n","                else:\r\n","                    pieces = vocab.encode_as_pieces(line)\r\n","                    if 0 < len(pieces):\r\n","                        doc.append(pieces)\r\n","                pbar.update(1)\r\n","        if doc:\r\n","            docs.append(doc)\r\n","\r\n","    for index in range(count):\r\n","        output = out_file.format(index)\r\n","        if os.path.isfile(output): continue\r\n","\r\n","        with open(output, \"w\") as out_f:\r\n","            with tqdm_notebook(total=len(docs), desc=f\"Making\") as pbar:\r\n","                for i, doc in enumerate(docs):\r\n","                    instances = create_pretrain_instances(docs, i, doc, n_seq, mask_prob, vocab_list)\r\n","                    for instance in instances:\r\n","                        out_f.write(json.dumps(instance))\r\n","                        out_f.write(\"\\n\")\r\n","                    pbar.update(1)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204,"referenced_widgets":["7bdc03ce61574c61990c857c185871b7","40ed58f8988c4694a416ea68d66c1304","9693d42f39cf4b1aa98b2a661cf24ada","5abc9cfac1e04179af8d329236aee3a0","b249c90a3331422d81b3eaf1f3e92b15","bbb6d71e3af44079ab9bede280621359","bcfe75f8a51143ccba6e53854521f5be","28937a8a7c1c4395bdb67258bf6d6428","2fd456dcda884509ae4193b116548c83","cc4c49ee557a4894ae7434e2654c09b4","a41b8eb0f737439d8763761e1a9f4a2f","759875c49b374910bd97be66b32a675f","0abeb44ca5e34b4d9ebc0f9662a7439f","653bde8d60f54ecca3c88336c43f790a","36c4819add474a7099828694b1029ea0","589d526e85594f4e9ad8ead4dfb8343f"]},"id":"dl0FiPALJ-vm","executionInfo":{"status":"ok","timestamp":1614827777445,"user_tz":-540,"elapsed":157226,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}},"outputId":"521ec63c-c6a0-465b-bcfc-bcc379082c20"},"source":["in_file = f\"{data_dir}/kowiki.txt\"\r\n","out_file = f\"{data_dir}/kowiki_bert\" + \"_{}.json\"\r\n","count = 1\r\n","n_seq = 256\r\n","mask_prob = 0.15\r\n","\r\n","make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  from ipykernel import kernelapp as app\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bdc03ce61574c61990c857c185871b7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Loading', max=3724301.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2fd456dcda884509ae4193b116548c83","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Making', max=100001.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kI3lHAWqKD5y"},"source":["Make Pretrain Dataset"]},{"cell_type":"code","metadata":{"id":"kGFWvO_FKHIS","executionInfo":{"status":"ok","timestamp":1614827777447,"user_tz":-540,"elapsed":157219,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["class PretrainDataSet(torch.utils.data.Dataset):\r\n","    def __init__(self, vocab, infile):\r\n","        self.vocab = vocab\r\n","        self.labels_cls = []\r\n","        self.labels_lm = []\r\n","        self.sentences = []\r\n","        self.segments = []\r\n","\r\n","        line_cnt = 0\r\n","        with open(infile, \"r\") as f:\r\n","            for line in f:\r\n","                line_cnt += 1\r\n","\r\n","        with open(infile, \"r\") as f:\r\n","            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\r\n","                instance = json.loads(line)\r\n","                self.labels_cls.append(instance[\"is_next\"])\r\n","                sentences = [vocab.piece_to_id(p) for p in instance[\"tokens\"]]\r\n","                self.sentences.append(sentences)\r\n","                self.segments.append(instance[\"segment\"])\r\n","                mask_idx = np.array(instance[\"mask_idx\"], dtype=np.int)\r\n","                mask_label = np.array([vocab.piece_to_id(p) for p in instance[\"mask_label\"]], dtype=np.int)\r\n","                label_lm = np.full(len(sentences), dtype=np.int, fill_value=-1)\r\n","                label_lm[mask_idx] = mask_label\r\n","                self.labels_lm.append(label_lm)\r\n","    \r\n","    def __len__(self):\r\n","        assert len(self.labels_cls) == len(self.labels_lm)\r\n","        assert len(self.labels_cls) == len(self.sentences)\r\n","        assert len(self.labels_cls) == len(self.segments)\r\n","        return len(self.labels_cls)\r\n","    \r\n","    def __getitem__(self, item):\r\n","        return (torch.tensor(self.labels_cls[item]),\r\n","                torch.tensor(self.labels_lm[item]),\r\n","                torch.tensor(self.sentences[item]),\r\n","                torch.tensor(self.segments[item]))"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Ihy70OZKVZr","executionInfo":{"status":"ok","timestamp":1614827777448,"user_tz":-540,"elapsed":157216,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["def pretrin_collate_fn(inputs):\r\n","    labels_cls, labels_lm, inputs, segments = list(zip(*inputs))\r\n","\r\n","    labels_lm = torch.nn.utils.rnn.pad_sequence(labels_lm, batch_first=True, padding_value=-1)\r\n","    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\r\n","    segments = torch.nn.utils.rnn.pad_sequence(segments, batch_first=True, padding_value=0)\r\n","\r\n","    batch = [\r\n","        torch.stack(labels_cls, dim=0),\r\n","        labels_lm,\r\n","        inputs,\r\n","        segments\r\n","    ]\r\n","    return batch"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XBrHxMCVKX6W","executionInfo":{"status":"ok","timestamp":1614827862236,"user_tz":-540,"elapsed":242000,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}},"outputId":"6e492410-4d81-4b15-97d0-648e9cc840e2"},"source":["batch_size = 128\r\n","dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_bert_0.json\")\r\n","train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Loading /content/drive/My Drive/Data/ML tutorial/kowiki_bert_0.json: 100%|██████████| 239857/239857 [01:23<00:00, 2863.71 lines/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"hO_7RS53KcFb"},"source":["Pretrain"]},{"cell_type":"code","metadata":{"id":"lfJgOJQDKaZZ","executionInfo":{"status":"ok","timestamp":1614827862239,"user_tz":-540,"elapsed":241999,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}}},"source":["def train_epoch(config, epoch, model, criterion_lm, criterion_cls, optimizer, train_loader):\r\n","    losses = []\r\n","    model.train()\r\n","\r\n","    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\r\n","        for i, value in enumerate(train_loader):\r\n","            labels_cls, labels_lm, inputs, segments = map(lambda v: v.to(config.device), value)\r\n","\r\n","            optimizer.zero_grad()\r\n","            outputs = model(inputs, segments)\r\n","            logits_cls, logits_lm = outputs[0], outputs[1]\r\n","\r\n","            loss_cls = criterion_cls(logits_cls, labels_cls)\r\n","            loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), labels_lm.view(-1))\r\n","            loss = loss_cls + loss_lm\r\n","\r\n","            loss_val = loss_lm.item()\r\n","            losses.append(loss_val)\r\n","\r\n","            loss.backward()\r\n","            optimizer.step()\r\n","\r\n","            pbar.update(1)\r\n","            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\r\n","    return np.mean(losses)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSIO0UWWKgoB","executionInfo":{"status":"ok","timestamp":1614827862513,"user_tz":-540,"elapsed":242269,"user":{"displayName":"Beanstalk Giant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjQW8P0anoxk4LoRCSxaOtj4FgzygkRISG0azTDQ=s64","userId":"04389221502269427900"}},"outputId":"693a0cd5-4848-4b5e-dbce-ed7a1333eafb"},"source":["config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n","print(config)\r\n","\r\n","learning_rate = 5e-5\r\n","n_epoch = 20"],"execution_count":22,"outputs":[{"output_type":"stream","text":["{'n_enc_vocab': 8007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda')}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rlrOBprfKize"},"source":["model = BERTPretrain(config)\r\n","\r\n","save_pretrain = f\"{data_dir}/save_bert_pretrain.pth\"\r\n","best_epoch, best_loss = 0, 0\r\n","if os.path.isfile(save_pretrain):\r\n","    best_epoch, best_loss = model.bert.load(save_pretrain)\r\n","    print(f\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\")\r\n","    best_epoch += 1\r\n","\r\n","model.to(config.device)\r\n","\r\n","criterion_lm = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean')\r\n","criterion_cls = torch.nn.CrossEntropyLoss()\r\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n","\r\n","losses = []\r\n","offset = best_epoch\r\n","for step in range(n_epoch):\r\n","    epoch = step + offset\r\n","    if 0 < step:\r\n","        del train_loader\r\n","        dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_bert_{epoch % count}.json\")\r\n","        train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)\r\n","\r\n","    loss = train_epoch(config, epoch, model, criterion_lm, criterion_cls, optimizer, train_loader)\r\n","    losses.append(loss)\r\n","    model.bert.save(epoch, loss, save_pretrain)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8FFSPSlQMn29","colab":{"base_uri":"https://localhost:8080/","height":931},"outputId":"34c02477-4241-4792-d187-efdccf22d9be"},"source":["# data\n","data = {\n","    \"loss\": losses\n","}\n","df = pd.DataFrame(data)\n","display(df)\n","\n","# graph\n","plt.figure(figsize=[12, 4])\n","plt.plot(losses, label=\"loss\")\n","plt.legend()\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>18.027608</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8.801137</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7.325305</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7.015369</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6.909906</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6.861085</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6.828222</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>6.804363</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>6.788513</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>6.774536</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>6.762376</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>6.751169</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>6.742494</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>6.736208</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>6.727837</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>6.724009</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>6.717879</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>6.711692</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>6.709890</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>6.707203</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         loss\n","0   18.027608\n","1    8.801137\n","2    7.325305\n","3    7.015369\n","4    6.909906\n","5    6.861085\n","6    6.828222\n","7    6.804363\n","8    6.788513\n","9    6.774536\n","10   6.762376\n","11   6.751169\n","12   6.742494\n","13   6.736208\n","14   6.727837\n","15   6.724009\n","16   6.717879\n","17   6.711692\n","18   6.709890\n","19   6.707203"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAs0AAAEGCAYAAACeiKhrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACAAgjNAAAAQAH/Df+XECQRmdb4AAAAAElFTkSuQmCC\n","text/plain":["<Figure size 864x288 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}